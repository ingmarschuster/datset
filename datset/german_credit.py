# -*- coding: utf-8 -*-
"""
Created on Sun May 17 15:09:01 2015

@author: Ingmar Schuster
"""

from __future__ import division, print_function, absolute_import

import numpy as np
import scipy as sp
import scipy.stats as stats

from numpy import exp, log, sqrt
from scipy.misc import logsumexp
from numpy.linalg import inv

import distributions as dist

from datset.tools import *

__all__ = ["credit_plain", "credit_plain_theano", "credit_hlr", "credit_hlr_theano", "credit_simple_is"]

def credit_plain(sigma):
    from  datset.data.german_credit import data_z as data
    
    (llab, llab_s) = log_sign(data[:,-1:])
    (lpred, lpred_s) = log_sign(data[:,:-1])
    
    def log_exp_term(alpha, beta):
        if len(beta.shape) <= 1:
            beta = beta[:,None]
        tmp = -(alpha+np.tensordot(data[:,:-1], beta, 1))

        if len(tmp.shape) == 3:
            rval = np.atleast_3d(data[:,-1:]) * tmp
        elif len(tmp.shape) == 2:
            rval = data[:,-1:] * tmp
        else:
            raise RuntimeError()
        #rval = -data[:,-1:]*(alpha+data[:,:-1].dot(beta))
        
        return rval
        
    def rval_lp_lgrad(param, grad = False, lpost = True):
        assert(len(param) == 25)
        alpha = param[:1]
        beta = param[1:]
        le = log_exp_term(alpha, beta)
        le_p1 = logsumexp((le, np.zeros_like(le)),0)

        if lpost:
            #assert(np.all(logsumexp((np.zeros_like(le), le),0) == log(1 + exp(le))))
            lp = (- le_p1.sum(0)
                    - 1/(2*sigma**2) * (alpha**2 + beta.dot(beta)))
                    
            if len(lp.shape) == 3:
                lp.shape = lp.shape[1:]
            if not grad:
                return lp
        if grad:
            #assert(not np.isnan(exp_le).any())
            #assert(not np.isinf(le).any())
        
            da = exp_sign(*logsumexp_sign(le - le_p1 + llab, axis = 0, sign = llab_s)) - 1/(sigma**2)*alpha
            db = exp_sign(*logsumexp_sign(le - le_p1 + llab + lpred, axis = 0, sign = llab_s * lpred_s)) - 1/(sigma**2)*beta
            #da = np.sum(exp(le-le_p1) * data[:,-1:], 0) - 1/(sigma**2)*alpha
            #db = np.sum(exp(le-le_p1) * data[:,-1:]*data[:,:-1], 0) - 1/(sigma**2)*beta
    
            lgrad = np.hstack((da, db))
            assert(lgrad.size==25)
            if not lpost:
                return lgrad
        return (lp, lgrad)
        
    rval_lpost = lambda param: rval_lp_lgrad(param, grad = False, lpost = True)
    
    rval_lgrad = lambda param: rval_lp_lgrad(param, grad = True, lpost = False)
    
    rval_lpost.opt5 = rval_lpost.opt10 = np.array([ 1.17903129,  0.72327228, -0.41081111,  0.40429438, -0.12126461,
        0.35671227,  0.17615053,  0.14985379, -0.01319223, -0.17613749,
        0.10723348,  0.22140805, -0.12024603, -0.03042954,  0.13299037,
        0.27224582, -0.27502516,  0.2889329 , -0.29613563, -0.26507539,
       -0.12209968,  0.06004149,  0.08724909,  0.02553138,  0.02414447]) #lpost: ~= -467.7

    return (rval_lpost, rval_lgrad, rval_lp_lgrad)


def credit_plain_theano(sigma):
    import theano.tensor as T
    import theano
    
    def LogSumExp(x, axis=None):
        x_max = T.max(x, axis=axis, keepdims=True)
        return T.log(T.sum(T.exp(x - x_max), axis=axis, keepdims=True)) + x_max
    
    from  datset.data.german_credit import data_z as data

    
    param = T.vector("param")
    alpha = param[0]
    beta = param[1:]
    ssq = sigma**2 # T.scalar("ssq")
    
    le = (-data[:,-1]*(alpha+T.tensordot(data[:,:-1], beta,1)))
    lpost = (- LogSumExp((le, T.zeros_like(le)),0).sum()
                    - 1/(2*ssq) * (alpha**2 + beta.dot(beta)))
    
    rval_lpost = theano.function([param], lpost[np.newaxis])
    rval_lgrad = theano.function([param],  T.grad(lpost, param))
    rval_lpost_lgrad_definitive = theano.function([param], [lpost, T.grad(lpost, param)])
    def rval_lpost_lgrad(x, grad=False):
        if grad:
            return rval_lpost_lgrad_definitive(x)
        else:
            return rval_lpost(x)
    rval_lhess = theano.function([param],  T.hessian(lpost, param))
    #rval_lpost_lgrad_lhess = theano.function([ab], [lpost, T.grad(lpost, ab), T.hessian(lpost, ab)])
    rval_lpost.start = np.array([ -7.06854908e-03,  -1.05940740e-03,  -2.22595260e-03,
        -1.76019755e-04,  -1.50490322e-02,   8.78030345e-03,
        -7.37716090e-03,  -7.12096046e-04,   2.63549291e-03,
        -2.72145365e-03,  -1.24480951e-03,   1.53656546e-03,
        -2.10982582e-03,   9.54294662e-03,   3.28415735e-03,
        -4.27019717e-03,  -5.40388605e-03,   1.59955152e-05,
        -8.39165505e-04,  -8.70450458e-03,   4.59230665e-03,
        -3.88058536e-03,   7.14414576e-04,   1.57565107e-03,
        -3.55516986e-04]) # -693.12774797
    rval_lpost.opt5 = rval_lpost.opt10 = np.array([ 1.17903129,  0.72327228, -0.41081111,  0.40429438, -0.12126461,
        0.35671227,  0.17615053,  0.14985379, -0.01319223, -0.17613749,
        0.10723348,  0.22140805, -0.12024603, -0.03042954,  0.13299037,
        0.27224582, -0.27502516,  0.2889329 , -0.29613563, -0.26507539,
       -0.12209968,  0.06004149,  0.08724909,  0.02553138,  0.02414447])
       
       
    rval_lpost.lev_10 = -504.50351534129481  # ess:64k
    
    rval_lpost.mean10 = np.array([ 1.21893714,  0.74425114, -0.42400969,  0.41887872, -0.12748981,
        0.36958792,  0.1803882 ,  0.15443886, -0.01343853, -0.18211756,
        0.1114502 ,  0.2275258 , -0.12446684, -0.02936427,  0.13928849,
        0.29929609, -0.28185025,  0.30380617, -0.31355048, -0.27824081,
       -0.12611041,  0.06059934,  0.0943746 ,  0.02720545,  0.0243925 ]) # ess:64k
    rval_lpost.var10 = np.array([ 0.00867382,  0.00819652,  0.01104309,  0.00920995,  0.01207431,
        0.00914813,  0.00863279,  0.00675966,  0.00845976,  0.01111273,
        0.00959999,  0.00631149,  0.00907294,  0.00741054,  0.00924893,
        0.01462468,  0.00692344,  0.01094516,  0.01530069,  0.01285691,
        0.01958964,  0.02130912,  0.0083684 ,  0.01677273,  0.01616993]) # ess:64k
    rval_lpost.var10_var = np.array([  1.48914629e-04,   1.36167635e-04,   2.45158971e-04,
         1.68000443e-04,   2.90601094e-04,   1.69721658e-04,
         1.48841302e-04,   9.24849836e-05,   1.41886621e-04,
         2.46041354e-04,   1.84995194e-04,   7.98114894e-05,
         1.63538115e-04,   1.09179820e-04,   1.69805356e-04,
         4.67226316e-04,   9.64438863e-05,   2.43413056e-04,
         4.90050751e-04,   3.36768963e-04,   7.68868104e-04,
         9.05877912e-04,   1.44516636e-04,   5.63252569e-04,
         5.32500054e-04])  # ess:64k
    return (rval_lpost, rval_lgrad, rval_lpost_lgrad,rval_lhess)#, rval_lpost_lgrad_lhess)


def credit_hlr_theano(lambd, transform = None, theano_symbol = False, neg=False, opt_grad=False):
    import theano.tensor as T
    import theano
    
    def LogSumExp(x, axis=None):
        x_max = T.max(x, axis=axis, keepdims=True)
        return T.log(T.sum(T.exp(x - x_max), axis=axis, keepdims=True)) + x_max
    
    from  datset.data.german_credit import data_z_2way as data

    
    param = T.vector("param")
    ssq = param[0]
    if transform is None:
        pass
    elif transform == "sp":
        ssq = T.nnet.softplus(ssq)
        
    alpha = param[1]
    beta = param[2:]
    
    le = (-data[:,-1]*(alpha+T.tensordot(data[:,:-1], beta,1)))
    lpost = (- LogSumExp((le, T.zeros_like(le)),0).sum()
                    - 1/(2*ssq) * (alpha**2 + beta.dot(beta)) - data.shape[0]/2*T.log(ssq)-lambd*ssq)
    if neg:
        lpost = -lpost
    if theano_symbol:
        return lpost
    else:             
        rval_lpost = theano.function([param], lpost[np.newaxis])
        rval_lgrad = theano.function([param],  T.grad(lpost, param))
        rval_lpost_lgrad = theano.function([param], [lpost, T.grad(lpost, param)])
        if not opt_grad:
            lp_lg = rval_lpost_lgrad
        else:
            def lp_lg(x, grad=False):
                if grad:
                    return rval_lpost_lgrad_definitive(x)
                else:
                    return rval_lpost(x)
        rval_lhess = theano.function([param],  T.hessian(lpost, param))
        
        rval_lpost.mean_0_01 = np.array([ -5.82814601e+00,   3.14978313e-01,   3.52003714e-01,
        -1.92538369e-01,   1.95932512e-01,  -1.42919210e-01,
         1.01028661e-01,   1.14296076e-01,   1.07127687e-01,
         6.49863745e-05,  -7.20196970e-02,   1.06381647e-01,
         1.22408564e-01,  -5.87318696e-02,   1.52747642e-02,
         7.62954378e-02,   1.23381749e-02,  -7.80079093e-02,
         1.26623924e-01,  -7.73410400e-02,   7.52715033e-03,
        -6.94296019e-02,   1.12564378e-01,  -5.85781173e-02,
        -3.45656782e-02,   6.64339814e-02,   9.23287683e-02,
        -5.66929217e-02,  -1.10931841e-01,  -7.08743854e-03,
         3.34047211e-02,  -2.23204563e-03,  -3.75047042e-03,
         1.02156056e-01,   9.55038580e-02,   1.10523823e-01,
        -3.08306294e-02,  -1.45974127e-02,  -4.87856871e-02,
        -2.71837120e-02,   1.35136042e-02,  -1.78903474e-02,
         1.22343521e-01,   1.61461441e-02,   6.10847520e-02,
         5.67062863e-02,   1.10320465e-01,   5.57693054e-03,
         9.80189237e-02,  -6.34472499e-03,   7.88931819e-02,
         1.38691863e-01,   5.44804452e-02,  -2.86782041e-02,
        -6.72432177e-02,   6.07712546e-02,  -5.15217708e-03,
         4.58985840e-02,   1.10550925e-02,   3.51846370e-03,
         4.08603638e-03,  -5.32808286e-02,   1.98120461e-02,
        -1.79207029e-03,   1.15525240e-01,   4.01357037e-02,
        -5.78030433e-02,   2.29509249e-02,   1.23682484e-01,
        -2.47500277e-02,  -4.88228402e-02,  -2.15629372e-04,
        -5.52883232e-02,  -1.57450538e-02,  -8.12326235e-04,
         3.93652482e-02,   8.51273163e-02,   6.46210191e-02,
         5.43861782e-02,   1.78535239e-01,   6.05872480e-02,
         1.85001330e-02,   2.75162799e-02,   2.10479620e-02,
         1.82327355e-02,   4.25831903e-02,   3.31461716e-02,
         7.00077440e-02,  -2.34007406e-02,  -2.00081483e-02,
        -5.02377206e-02,  -4.66852178e-02,   1.23913377e-02,
        -4.23273222e-02,  -9.36358433e-03,   1.95769743e-02,
        -1.45446395e-02,  -4.10209084e-02,  -3.65709957e-02,
        -4.80843853e-02,   6.45925650e-02,  -1.29616776e-01,
        -1.80665199e-02,  -1.55198215e-02,   1.47977388e-02,
         5.67754612e-03,  -1.98264074e-03,  -1.32813363e-02,
        -6.57790729e-03,  -3.47394576e-02,   1.86773662e-02,
         1.56500390e-02,   2.74034178e-02,  -4.54125948e-02,
         5.22530815e-02,  -3.59885367e-02,  -6.07692006e-02,
        -6.24162324e-03,  -3.82619321e-02,  -7.72510140e-03,
         1.08080624e-01,   2.12086781e-02,   8.59135644e-03,
         5.01570169e-02,   2.66517317e-02,  -2.83733862e-02,
         6.79125822e-03,  -4.09460962e-02,   7.15654350e-02,
         5.92711110e-02,   1.52215256e-02,  -1.18995055e-02,
         4.10227802e-03,  -1.52787920e-02,  -3.86180725e-02,
         4.72408385e-02,   6.72008107e-02,  -1.56729597e-02,
         1.30328142e-02,  -6.12851330e-02,  -7.43982918e-02,
        -3.36906703e-02,   6.62393185e-03,   9.44574988e-03,
         6.92407469e-03,   4.05769897e-02,  -9.01073239e-02,
         8.30291081e-02,  -2.05900708e-03,   4.53124959e-02,
        -8.27943430e-02,  -5.94465812e-02,   8.69235803e-03,
         2.77162099e-03,   9.86773935e-03,   2.47398734e-02,
         3.16626264e-02,  -8.37365285e-03,   7.12304418e-02,
         8.66333889e-02,   5.05393608e-02,  -3.92012380e-02,
        -4.95773881e-02,   9.89670208e-02,  -3.51730150e-02,
        -6.94446270e-02,  -5.03420838e-02,   4.08503253e-02,
         5.35328032e-04,  -5.10412271e-03,  -1.56959452e-02,
         1.31034914e-02,  -1.12345907e-01,   4.38671181e-02,
         3.87443884e-03,  -9.24599707e-02,  -6.35104920e-02,
         2.40360806e-02,  -2.54854622e-02,   8.15316569e-02,
        -6.00970805e-03,   4.82957134e-02,  -3.58946409e-02,
        -5.38162590e-02,  -1.82273919e-02,  -5.33975200e-02,
        -3.44344131e-02,  -1.51681061e-01,   6.39574447e-02,
         6.36647832e-02,   4.44661435e-02,   5.36712965e-02,
        -4.28999680e-02,  -4.41245058e-02,  -4.27271979e-02,
        -1.44718357e-01,   5.98886936e-03,  -6.71206634e-03,
        -7.20686815e-02,  -2.16317742e-02,   4.90807405e-02,
         7.00916197e-02,   6.51307058e-02,   3.17493943e-02,
         8.61001965e-03,   1.33525972e-02,   3.49241713e-02,
         4.30313798e-02,   7.91185705e-02,  -2.97460972e-02,
        -1.85462933e-02,  -3.19579349e-02,   5.47089224e-02,
        -4.37099140e-02,  -1.46328569e-03,   9.80062075e-02,
         4.12449858e-02,  -1.41637973e-02,  -3.98256617e-02,
         1.57664488e-01,   5.81368889e-03,  -6.93456484e-02,
         1.98711623e-03,   2.07291327e-02,   5.20472006e-02,
        -1.22671085e-02,  -6.53709141e-02,  -4.87304877e-02,
        -4.87071951e-02,   3.97955926e-02,  -1.90586440e-02,
        -2.53127956e-02,   4.38377152e-02,  -3.54926350e-02,
         1.40641394e-01,   6.97444719e-02,   7.75849176e-02,
        -4.37987052e-02,   6.25130027e-02,   4.18185601e-02,
        -8.49780137e-02,  -1.07929408e-01,   6.21691483e-02,
         2.68965815e-02,  -2.69500870e-04,  -2.95380628e-02,
        -3.93319360e-02,  -7.58873313e-02,   3.40603292e-02,
         8.02563561e-02,  -4.96209762e-02,  -4.52178097e-02,
        -1.88815208e-02,  -3.80705985e-02,   3.89332721e-02,
        -1.19220237e-01,  -6.30055768e-02,   6.56104445e-02,
         1.58198077e-02,   1.18675364e-02,  -1.33286250e-02,
         1.30352385e-01,  -6.24571796e-02,  -5.29349441e-02,
         1.08508692e-01,   1.34018421e-01,  -2.32455678e-02,
         3.74051096e-02,   3.14300757e-04,  -3.35575419e-02,
         6.01545078e-02,   2.47715515e-02,  -2.82919481e-02,
        -2.21305885e-02,  -3.60787501e-02,   1.99966662e-02,
         6.19699426e-02,   3.94947014e-02,   4.10472167e-02,
         3.06671465e-03,  -4.68702595e-02,   5.10116525e-02,
         6.51153261e-02,  -7.08458459e-02,  -5.07397439e-02,
        -4.96671983e-02,  -2.49287273e-02,  -4.98582609e-02,
        -3.17000869e-02,  -1.49020220e-02,   5.49923366e-02,
        -4.43173901e-02,  -1.40576490e-01,   1.16792670e-02,
        -2.63318787e-02,  -6.34709905e-02,  -1.13698374e-01,
        -2.46789841e-02,   4.72761973e-02,  -9.01196867e-02,
        -1.03451803e-01,  -9.45046062e-02]) # 100k samples Adapt.Metr. acc rate 0.2245
        
        rval_lpost.var_0_01 = np.array([  3.69072114e+00,   7.13821081e-02,   6.05137653e-02,
         2.28331342e-02,   2.27334198e-02,   2.14731131e-02,
         1.34615287e-02,   1.29472762e-02,   1.16681104e-02,
         7.34762684e-03,   2.54802257e-03,   9.12970054e-03,
         1.16309721e-02,   7.54503351e-03,   9.25878284e-03,
         1.60019102e-02,   8.98549939e-03,   7.72686525e-03,
         1.96737612e-02,   8.28677952e-03,   7.34114510e-03,
         1.01407371e-02,   1.47649023e-02,   1.05555260e-02,
         8.06050137e-03,   1.64049968e-02,   1.86842320e-02,
         4.19130066e-03,   1.91650072e-02,   2.05055210e-03,
         7.57263702e-03,   6.17432027e-03,   1.47711748e-02,
         8.50794148e-03,   1.45323043e-02,   1.47896717e-02,
         4.00588847e-03,   6.87197282e-03,   9.57958391e-03,
         7.72554502e-03,   9.23225759e-03,   4.54869157e-03,
         2.25692194e-02,   2.60844010e-03,   1.90338793e-02,
         9.19477881e-03,   2.07743697e-02,   6.18330264e-03,
         1.17033832e-02,   8.03261740e-03,   6.52510387e-03,
         2.56779419e-02,   2.94266795e-03,   5.50552111e-03,
         9.24749781e-03,   1.60343346e-02,   7.90358233e-03,
         6.27222551e-03,   8.22912677e-03,   6.81475417e-03,
         1.04667480e-02,   8.94035793e-03,   4.99031555e-03,
         4.51240214e-03,   1.75875279e-02,   9.37243154e-03,
         8.57200471e-03,   3.31748452e-03,   9.65992252e-03,
         1.10327057e-02,   5.82688569e-03,   8.43503114e-03,
         1.12834106e-02,   9.77663786e-03,   5.68603537e-03,
         1.77294639e-02,   1.22308097e-02,   1.37544611e-02,
         4.47182604e-03,   1.10908679e-02,   2.22211674e-02,
         9.88871700e-03,   4.09221098e-03,   3.26759286e-03,
         5.38383101e-03,   5.38704028e-03,   7.61846831e-03,
         1.42122900e-02,   3.30308801e-03,   7.31792997e-03,
         5.37955687e-03,   5.16858995e-03,   9.10238072e-03,
         7.56944105e-03,   4.71626753e-03,   5.62159919e-03,
         1.07512027e-02,   1.42677858e-02,   9.79975068e-03,
         4.81900224e-03,   1.13001713e-02,   1.64499391e-02,
         4.42937638e-03,   2.24380391e-02,   5.04397320e-03,
         1.01018186e-02,   3.65991115e-03,   8.31199042e-03,
         9.02084457e-03,   8.37652766e-03,   2.17031358e-02,
         7.31896527e-03,   1.45161711e-02,   7.34889726e-03,
         4.11986681e-03,   5.66159866e-03,   7.92708701e-03,
         2.73715090e-03,   1.14086743e-02,   4.05975396e-03,
         2.13522061e-02,   3.92967002e-03,   3.28905459e-03,
         5.47898402e-03,   1.06012679e-02,   1.63430303e-02,
         6.99756044e-03,   3.84504001e-03,   6.11982601e-03,
         1.79017409e-02,   6.12122669e-03,   1.18931324e-02,
         6.41047380e-03,   4.26898408e-03,   3.44134335e-03,
         7.95820910e-03,   1.14149384e-02,   1.47659056e-02,
         4.67139131e-03,   1.14050845e-02,   1.30447117e-02,
         4.55623139e-03,   1.36386515e-02,   9.21060612e-03,
         1.15103842e-02,   1.10690795e-02,   8.63271340e-03,
         6.24027929e-03,   2.77256199e-03,   3.95014744e-03,
         4.97045944e-03,   4.80899507e-03,   1.05673660e-02,
         2.50905435e-03,   6.52863516e-03,   3.84451797e-03,
         3.04360408e-02,   6.37650329e-03,   7.28879472e-03,
         8.94213591e-03,   3.51025987e-02,   7.58131356e-03,
         1.15370898e-02,   2.01631460e-02,   7.63882382e-03,
         5.96985486e-03,   1.35456294e-02,   8.33946910e-03,
         6.59028444e-03,   8.26801259e-03,   1.56634662e-02,
         5.29471867e-03,   3.34959621e-02,   6.03941283e-03,
         1.06690786e-02,   1.28996196e-02,   1.10078316e-02,
         1.39506043e-02,   2.06929131e-02,   2.38137662e-02,
         4.80937597e-03,   6.07496409e-03,   7.27416826e-03,
         6.99602558e-03,   4.24324089e-03,   1.04408719e-02,
         1.10880760e-02,   1.70267671e-02,   1.57397161e-02,
         5.30892923e-03,   7.88785747e-03,   7.88480219e-03,
         9.33245522e-03,   4.52805145e-03,   2.17651508e-02,
         2.77906530e-02,   2.57485917e-02,   3.65327131e-03,
         1.94264743e-02,   1.19873272e-02,   1.02593533e-02,
         1.95566164e-02,   6.56172111e-03,   6.56725294e-03,
         5.07650605e-03,   2.62529400e-03,   9.23581084e-03,
         1.84072661e-02,   5.58894515e-03,   5.24305866e-03,
         4.43535770e-03,   4.95985749e-03,   3.72988322e-03,
         2.49674993e-03,   4.16141967e-03,   7.03678263e-03,
         1.13716470e-02,   2.92940433e-03,   5.36121374e-03,
         3.17394487e-02,   8.48457408e-03,   6.39853287e-02,
         5.26648147e-03,   5.93780926e-03,   8.43673440e-03,
         7.03386711e-03,   3.07300499e-02,   1.04416713e-02,
         8.80917903e-03,   7.82940277e-03,   3.29028393e-03,
         1.14883914e-02,   6.59996251e-03,   1.28834844e-02,
         1.60459243e-02,   7.36510504e-03,   4.80298857e-03,
         7.37551895e-03,   8.07368455e-03,   1.31876628e-02,
         5.96628257e-03,   1.55726056e-02,   1.25400647e-02,
         4.74142359e-03,   1.16022710e-02,   4.77030732e-03,
         9.78930257e-03,   6.07339365e-03,   1.04280002e-02,
         1.23551529e-02,   1.09447421e-02,   1.06545988e-02,
         2.38464010e-03,   7.20320610e-03,   6.56377432e-03,
         1.84791856e-02,   3.16628553e-02,   1.39704701e-02,
         3.13483204e-02,   9.84163554e-03,   4.47578468e-03,
         2.44815786e-02,   5.92552570e-03,   7.35065924e-03,
         8.66195219e-03,   2.12497696e-02,   7.16658043e-03,
         1.13027782e-02,   9.88861545e-03,   5.00574950e-03,
         7.79083802e-03,   2.53402895e-03,   6.82569623e-03,
         3.51497904e-03,   8.99734630e-03,   7.04219046e-03,
         5.69748805e-03,   1.69375675e-02,   8.74222457e-03,
         1.16175957e-02,   1.07759559e-02,   3.60055793e-03,
         2.89830177e-03,   1.82191439e-02,   2.89681575e-02,
         2.47393736e-03,   3.96521172e-03,   1.46313353e-02,
         6.00461213e-03,   4.23278735e-03,   7.12827951e-03,
         1.09400411e-02,   9.27366567e-03,   1.20186187e-02,
         4.59731192e-03,   1.93190418e-02,   4.57377639e-02,
         7.17074013e-03,   2.52960229e-02,   2.07162880e-02,
         1.97147725e-02,   1.09530725e-02])# 100k samples Adapt.Metr. acc rate 0.2245
         
        rval_lpost.var_0_01_var = np.array([  2.41329732e+01,   1.48836538e-02,   3.84665162e-03,
         1.08018906e-03,   6.61415593e-04,   9.54849751e-04,
         4.25603113e-04,   3.68331016e-04,   1.54420090e-04,
         3.56829783e-04,   2.40494051e-05,   1.41722195e-04,
         1.70207152e-04,   2.37682673e-04,   1.77870145e-04,
         7.37777265e-04,   1.75173041e-04,   3.16263925e-04,
         1.12871342e-03,   2.02853178e-04,   2.12793549e-04,
         2.15950121e-04,   1.20034860e-03,   5.33022130e-04,
         5.15440745e-04,   8.66237720e-04,   1.54256057e-03,
         5.37580952e-05,   1.02568170e-03,   7.39599659e-06,
         1.17579599e-04,   4.12948747e-04,   1.22977347e-03,
         1.07811374e-04,   3.56693797e-04,   2.81222260e-04,
         1.06664718e-04,   1.72068273e-04,   3.34282296e-04,
         2.71035492e-04,   3.92947495e-04,   5.11277673e-05,
         2.08885017e-03,   7.37778826e-05,   1.73666240e-03,
         2.39401168e-04,   1.16494599e-03,   5.23562889e-05,
         2.36578795e-04,   1.84633191e-04,   5.75493324e-05,
         8.68005512e-04,   3.49016329e-05,   1.09879055e-04,
         4.85783047e-04,   1.07010128e-03,   2.88927636e-04,
         9.22527849e-05,   1.50108253e-04,   1.86233829e-04,
         5.36158837e-04,   2.53410180e-04,   1.94778761e-04,
         6.47025206e-05,   7.98179644e-04,   5.94517105e-04,
         1.83376883e-04,   4.83888447e-05,   2.97372048e-04,
         3.50735345e-04,   9.61854624e-05,   1.18163298e-04,
         4.36567259e-04,   7.63442262e-04,   2.37426753e-04,
         1.79068181e-03,   6.34615660e-04,   1.78828995e-03,
         9.07776167e-05,   1.62164407e-04,   2.83235944e-03,
         3.78727921e-04,   7.06238687e-05,   2.58422972e-05,
         1.12417388e-04,   1.08131184e-04,   2.12204957e-04,
         6.70713885e-04,   3.79111070e-05,   1.95882703e-04,
         6.14625605e-05,   6.91734582e-05,   2.34208495e-04,
         3.26346613e-04,   5.87854253e-05,   1.50811860e-04,
         3.53996147e-04,   8.41620564e-04,   8.23877507e-04,
         4.02110477e-05,   1.65846181e-04,   4.85720597e-04,
         5.25168312e-05,   1.92986674e-03,   7.63726085e-05,
         2.68385632e-04,   3.49899999e-05,   3.84238474e-04,
         9.41723575e-04,   2.24531793e-04,   1.71008086e-03,
         1.58846156e-04,   2.09331634e-03,   7.95817456e-04,
         4.02402492e-05,   2.38817375e-04,   1.86858123e-04,
         4.38787804e-05,   3.87938916e-04,   3.95330390e-05,
         1.73983938e-03,   4.54889114e-05,   3.06252658e-05,
         1.37388475e-04,   1.66257462e-04,   7.20594220e-04,
         5.07651975e-04,   2.13899067e-05,   8.99185709e-05,
         8.42418904e-04,   9.40579211e-05,   8.00868065e-04,
         1.77358223e-04,   7.84609338e-05,   4.66901772e-05,
         4.96999172e-04,   8.38299056e-04,   7.75170208e-04,
         4.63524322e-05,   9.73800240e-04,   5.18860102e-04,
         9.17008581e-05,   1.99041110e-03,   3.98739549e-04,
         1.01954654e-03,   6.22489056e-04,   3.21772247e-04,
         1.05208674e-04,   3.03365026e-05,   6.12380243e-05,
         5.82456826e-05,   1.82977552e-04,   4.03769392e-04,
         3.96717247e-05,   9.00605039e-05,   4.54290024e-05,
         4.13687073e-03,   2.76091122e-04,   1.97109973e-04,
         2.69047895e-04,   6.23878974e-03,   5.92954727e-04,
         5.55868629e-04,   5.79443413e-04,   2.19539137e-04,
         1.62436097e-04,   7.53026693e-04,   5.34098838e-04,
         6.30253201e-04,   3.23302073e-04,   2.66335698e-03,
         1.54562481e-04,   4.09259937e-03,   6.20867122e-05,
         9.29665694e-04,   3.40100929e-04,   3.18465953e-04,
         9.58116446e-04,   2.78977632e-03,   1.34922500e-03,
         9.71848279e-05,   9.56194162e-05,   1.60727893e-04,
         8.16045063e-05,   3.79527637e-05,   2.97479862e-04,
         1.68881842e-04,   6.50092979e-04,   6.04928250e-04,
         6.04328277e-05,   2.49301172e-04,   2.43542058e-04,
         3.90267121e-04,   5.49531784e-05,   2.01650384e-03,
         1.86627800e-03,   2.92534494e-03,   3.77105865e-05,
         9.51102512e-04,   5.78761184e-04,   5.65279269e-04,
         1.62163281e-03,   7.73420730e-05,   1.06476849e-04,
         6.89981255e-05,   1.79630369e-05,   1.08572901e-04,
         2.58497145e-03,   5.75741262e-05,   9.32107438e-05,
         1.24206852e-04,   6.68427471e-05,   4.52709417e-05,
         1.75620589e-05,   6.18155755e-05,   5.91604868e-05,
         4.54536237e-04,   1.03254797e-04,   1.61712169e-04,
         1.28909517e-03,   4.25597241e-04,   9.89843886e-03,
         1.14685169e-04,   1.87584519e-04,   3.54380593e-04,
         1.60927719e-04,   5.57931647e-03,   1.14297192e-03,
         6.86365825e-04,   1.55965452e-04,   3.99885441e-05,
         3.89444065e-04,   2.01666413e-04,   5.69242385e-04,
         2.29412855e-04,   1.91724417e-04,   4.66408545e-05,
         1.78222639e-04,   2.19163245e-04,   1.20159936e-03,
         3.81425274e-05,   3.37815359e-04,   4.74905683e-04,
         1.18566776e-04,   1.06066177e-03,   7.66867879e-05,
         2.93649047e-04,   1.03765973e-04,   6.65155298e-04,
         5.63354054e-04,   1.64547366e-04,   2.46974754e-04,
         4.03076963e-05,   2.16770935e-04,   2.15811940e-04,
         6.34837300e-04,   1.62985917e-03,   8.12563886e-04,
         1.75193999e-03,   3.31936016e-04,   1.04809042e-04,
         1.28370700e-03,   6.95565146e-05,   2.76946586e-04,
         1.99333906e-04,   9.62937954e-04,   2.16398267e-04,
         2.23173657e-04,   6.30753465e-04,   6.54373374e-05,
         1.53898839e-04,   4.41548798e-05,   4.45998377e-04,
         4.74209390e-05,   7.08038027e-04,   1.14899398e-04,
         1.33255448e-04,   1.80380719e-03,   2.58526786e-04,
         3.55261882e-04,   6.66404104e-04,   5.44269685e-05,
         2.56481196e-05,   1.75310135e-03,   2.74545386e-03,
         1.58582734e-05,   1.65861060e-04,   7.33425017e-04,
         1.75289600e-04,   6.15050643e-05,   2.08180713e-04,
         3.78933550e-04,   1.31869704e-04,   6.56294670e-04,
         7.19415385e-05,   1.78777927e-03,   6.75599863e-03,
         1.90024542e-04,   3.68577337e-03,   3.05902013e-03,
         9.71532091e-04,   1.97887587e-04])# 100k samples Adapt.Metr. acc rate 0.2245
        
        rval_lpost.opt_0_01 = np.array([  1.48330894e-03,   2.32123189e-01,   2.10581621e-01, #without transforms
        -1.37343452e-01,   1.10535811e-01,  -5.34547911e-02,
         9.76128206e-02,   7.31552147e-02,   3.39595702e-02,
         1.09578012e-02,  -5.64125001e-02,   2.32323899e-02,
         6.61636971e-02,  -2.27567000e-02,   7.64824332e-03,
         1.64770910e-02,   2.56178157e-02,  -7.48164442e-02,
         7.82501141e-02,  -3.28552764e-02,  -1.74748743e-02,
        -5.37079683e-02,   6.60081787e-02,  -1.15141308e-02,
        -8.03231759e-03,   9.45767737e-06,   5.70771504e-02,
        -1.67812530e-02,  -4.63400058e-02,  -5.93271569e-03,
         4.84038000e-02,  -1.04979823e-03,   6.78325490e-03,
         3.85596778e-02,   1.31623568e-02,   5.17508343e-02,
        -2.03388354e-02,  -1.97031214e-02,   6.88271876e-04,
        -1.88241566e-02,   3.14845811e-03,   1.09737749e-02,
         6.33233867e-02,   2.44021354e-03,  -2.38332689e-02,
         1.04791926e-02,   1.52008087e-02,  -1.97676826e-02,
         5.60896981e-02,  -4.47555813e-02,   8.93739911e-02,
         6.88181332e-02,   2.50701685e-02,  -1.49262635e-05,
        -2.30763314e-02,   4.15521456e-02,   9.47263938e-03,
         1.83105780e-02,  -1.81995132e-02,  -6.73780916e-04,
         6.14959633e-02,  -3.54029263e-02,  -8.99008201e-03,
         5.93523924e-02,   3.07826246e-02,   1.47499306e-02,
        -5.04738819e-02,  -9.85327035e-03,   1.22732344e-02,
        -7.20580520e-02,  -5.02610361e-03,   1.80339148e-02,
        -2.43079224e-02,   1.42379856e-02,   2.00284754e-03,
         2.50452469e-02,   2.48632110e-02,   5.59120116e-02,
         5.69747396e-02,   1.29797762e-01,   1.60026879e-02,
         1.33449534e-02,  -6.88846417e-03,   1.85348841e-02,
         5.97326029e-03,   4.36514427e-02,   2.63778710e-02,
         1.88591045e-03,  -2.00610537e-02,   3.05143298e-02,
        -9.41296531e-03,   7.73652683e-05,   3.90191492e-02,
        -2.82429583e-02,   5.16560747e-03,   2.38133607e-02,
         3.26736525e-02,  -1.94812850e-02,  -4.97476918e-03,
        -3.28829506e-03,   2.13963887e-02,  -6.14751449e-02,
        -5.48245043e-02,   2.41075493e-03,  -1.37561933e-02,
         1.02916355e-02,  -1.74604813e-03,  -3.56202427e-03,
        -9.15419132e-03,  -1.95489034e-02,   3.83475646e-02,
        -4.16735482e-03,   1.00511269e-02,  -3.02719311e-02,
         4.19490416e-02,   1.14798812e-02,  -3.85734442e-03,
        -1.44240622e-02,  -1.90316999e-02,   1.48070301e-02,
         2.57163554e-02,   2.80255108e-02,  -2.80932636e-02,
         1.11571743e-02,   4.54924821e-02,   2.58996220e-02,
         2.61509917e-02,   1.33785099e-02,   3.78600636e-02,
        -1.05038886e-03,   9.08467607e-03,   1.60464047e-02,
         1.49192491e-02,   1.24314205e-03,   9.77079537e-03,
         1.70685547e-02,   2.60251044e-02,   8.03313091e-03,
         6.61072719e-03,  -3.97656720e-02,  -3.12861622e-02,
        -1.57039823e-02,   3.50513532e-02,   1.69355309e-02,
         3.07620083e-02,   2.47554908e-02,  -4.09233509e-02,
         1.63744636e-02,   1.91192252e-02,   3.65160711e-03,
        -4.13080242e-02,  -3.98164336e-02,  -2.18264779e-02,
         1.28016878e-02,   1.07371236e-02,  -8.79462872e-04,
         2.22773041e-02,   1.51235942e-03,   8.03865994e-03,
         2.87451660e-02,   1.97441906e-02,  -1.21854171e-02,
        -1.70303673e-02,   1.94899251e-02,   1.77271892e-02,
        -1.73663615e-03,  -7.90606040e-03,   4.42908550e-02,
         3.19946887e-02,  -9.03399993e-03,  -7.27845673e-03,
         3.91284433e-02,  -1.26320496e-02,   2.10613945e-02,
         1.14229846e-02,   4.27058281e-03,   1.69271094e-02,
         3.73949411e-02,  -2.98521676e-02,   1.64118414e-02,
        -2.65196500e-03,   1.76838922e-02,  -3.20983118e-02,
        -3.88779462e-02,  -1.97898139e-02,  -5.87389934e-02,
         3.27699047e-02,  -2.38977478e-02,  -9.73785074e-03,
         5.66540379e-02,   4.45371164e-02,   3.05180597e-02,
        -3.23245188e-02,  -5.37416689e-02,  -1.50999264e-02,
        -1.07079811e-01,   2.27276551e-02,   4.66713189e-03,
         4.31241791e-03,  -6.16783079e-03,   2.62164314e-02,
        -9.96499874e-03,   6.25358185e-02,  -1.59782510e-02,
        -2.03834467e-03,  -2.11435432e-02,  -2.56492270e-02,
         1.54577296e-02,   5.17533530e-02,   9.52093930e-03,
        -1.42424343e-02,  -2.35835914e-02,   1.52108804e-02,
        -1.95170204e-02,  -6.06709147e-03,   6.14514010e-02,
        -4.78882510e-03,   1.55438378e-03,  -1.34556524e-02,
         4.80654392e-02,   7.06766890e-04,  -2.85965676e-02,
         1.07643140e-02,   5.20248852e-02,   3.43185108e-02,
        -5.21632297e-03,   7.86715148e-04,  -1.94046947e-02,
        -9.96072704e-03,   1.71061532e-02,  -1.36344908e-02,
        -4.19952211e-02,   4.57279153e-02,   3.54418407e-03,
         3.49428199e-02,  -1.47009512e-03,   4.89579855e-02,
         5.02867685e-02,   5.94545896e-02,   1.38900884e-02,
        -5.12376900e-02,  -4.64849999e-02,   1.50191026e-02,
         2.45199374e-02,  -2.70030891e-02,   1.72061375e-02,
        -3.32215924e-02,  -3.69152504e-02,   1.33135692e-02,
         3.07855550e-02,   9.58427742e-03,  -1.25760648e-02,
         1.23400158e-02,  -2.02094775e-02,   2.11168297e-03,
        -4.94346307e-02,   2.17070643e-02,   6.12825425e-02,
         5.06400667e-03,  -1.37552458e-02,   2.83468352e-02,
         6.15868624e-03,   7.74285635e-03,   1.37415361e-02,
         6.34516122e-02,  -9.63845455e-03,  -6.13713091e-02,
         4.20455719e-02,   1.19717616e-03,  -1.31413102e-02,
         3.06006270e-03,   4.27981091e-02,  -9.58403999e-04,
        -2.26399082e-02,  -9.83366353e-03,  -7.62603959e-03,
         6.89370095e-03,  -1.22740820e-02,   7.00931281e-03,
        -6.31101464e-02,  -1.69374814e-02,  -8.85205697e-02,
         3.80205252e-02,  -4.15448766e-03,   9.88235052e-03,
        -1.08853074e-04,   7.02349341e-03,  -3.89461386e-02,
         2.90273673e-03,   1.47432234e-03,  -8.24054746e-04,
        -3.96488889e-02,  -1.17003556e-01,   3.89862183e-02,
        -7.29617434e-03,  -6.32151059e-04,   8.32364318e-03,
         3.88253331e-02,   5.55654248e-02,  -1.04454851e-02,
        -3.04055521e-02,  -1.40969595e-01])
        return (rval_lpost, rval_lgrad, lp_lg, rval_lhess)

def credit_hlr(lambd, softplus_transform = False):
    from  datset.data.german_credit import data_z_2way as data
    
    (llab, llab_s) = log_sign(data[:,-1:])
    (lpred, lpred_s) = log_sign(data[:,:-1])
    
    if softplus_transform:
        transf = lambda par0: log(1+exp(par0))
    else:
        transf = lambda par0: par0
    
    def log_exp_term(alpha, beta):
        if len(beta.shape) <= 1:
            beta = beta[:,None]
        tmp = -(alpha+np.tensordot(data[:,:-1], beta, 1))

        if len(tmp.shape) == 3:
            rval = np.atleast_3d(data[:,-1:]) * tmp
        elif len(tmp.shape) == 2:
            rval = data[:,-1:] * tmp
        else:
            raise RuntimeError()
        #rval = -data[:,-1:]*(alpha+data[:,:-1].dot(beta))
        
        return rval
        
    def rval_lp_lgrad(param, grad = False, lpost = True):
        assert(len(param) == 302)      
        sigmasq = transf(param[0])
        assert(sigmasq > 0)
        
        alpha = param[1:2]
        beta = param[2:]
        alsq_p_betsq = alpha**2 + beta.dot(beta)
        le = log_exp_term(alpha, beta)
        le_p1 = logsumexp((le, np.zeros_like(le)),0)

        if lpost:
            #assert(np.all(logsumexp((np.zeros_like(le), le),0) == log(1 + exp(le))))
            lp = (- le_p1.sum(0)
                    - 1/(2*sigmasq) * alsq_p_betsq
                    - data.shape[0]/2*log(sigmasq)-lambd*sigmasq)
            if len(lp.shape) == 3:
                lp.shape = lp.shape[1:]
            #assert()
            if not grad:
                return lp
        if grad:
            #assert(not np.isnan(exp_le).any())
            #assert(not np.isinf(le).any())
        
            da = exp_sign(*logsumexp_sign(le - le_p1 + llab, axis = 0, sign = llab_s)) - 1/(sigmasq)*alpha
            dssq = alsq_p_betsq/(2*sigmasq**2) - lambd - data.shape[0]/(2*sigmasq)
            db = exp_sign(*logsumexp_sign(le - le_p1 + llab + lpred, axis = 0, sign = llab_s * lpred_s)) - 1/(sigmasq)*beta

            #da = np.sum(exp(le-le_p1) * data[:,-1:], 0) - 1/(sigma**2)*alpha
            #db = np.sum(exp(le-le_p1) * data[:,-1:]*data[:,:-1], 0) - 1/(sigma**2)*beta
    
            lgrad = np.hstack((dssq, da, db))
            assert(lgrad.size==302)
            if not lpost:
                return lgrad
        return (lp, lgrad)
        
    rval_lpost = lambda param: rval_lp_lgrad(param, grad = False, lpost = True)
    
    rval_lgrad = lambda param: rval_lp_lgrad(param, grad = True, lpost = False)
    
    rval_lpost.opt_0_01 = np.array([  1.10603710e-07,  -1.00498968e-03,  -2.08838669e-03,
        -4.36793740e-05,  -1.32672098e-03,   8.44761326e-04,
        -1.69426660e-03,  -7.40781813e-04,  -7.86501422e-04,
         2.41702840e-04,   6.29503833e-04,  -1.03329870e-03,
        -3.32851354e-04,  -1.10064901e-03,   4.89766183e-04,
        -8.95457462e-04,   2.75004222e-04,   8.12176681e-04,
        -3.13342095e-04,  -1.61415782e-03,   1.51315668e-03,
         5.41609789e-04,  -8.38312963e-04,   2.35193638e-04,
         1.45629626e-03,  -1.49412626e-03,   3.07492281e-04,
        -5.92730223e-04,  -2.87807465e-04,  -3.49179813e-04,
         1.87811350e-04,   1.86751471e-05,   2.24568838e-04,
        -1.47984762e-04,   2.24384503e-04,  -6.66247060e-04,
        -5.19378772e-04,   4.23460142e-04,  -2.52747683e-04,
        -2.35266867e-04,  -4.87311684e-04,   1.95654196e-04,
        -5.95809481e-04,   5.61573768e-04,   7.70634006e-05,
        -8.28568513e-05,   1.30868293e-04,   4.85607697e-04,
        -2.80195007e-04,  -1.44238227e-04,   6.50051699e-04,
        -8.98059964e-04,  -3.14369645e-04,  -4.49364391e-04,
         1.08769941e-04,  -3.32504581e-05,   4.06052611e-04,
         1.37036314e-03,   6.98708906e-05,  -1.13796402e-03,
         8.86440744e-04,   3.41442490e-04,  -7.78803531e-04,
        -5.77707800e-04,  -1.73904049e-04,   2.57591376e-04,
         3.50954216e-04,  -7.25658517e-04,   3.32545732e-04,
        -1.16277753e-03,   4.43670887e-04,   6.30398502e-04,
        -3.59821315e-05,  -8.54271351e-04,   5.11772204e-04,
         9.60347854e-05,   1.57995730e-04,   4.32009249e-04,
        -6.23974730e-04,  -1.27644955e-03,   4.99053295e-06,
         2.63282558e-04,   5.12797508e-04,   2.95963062e-04,
         2.20677572e-05,  -2.93732883e-04,   7.70287040e-04,
         3.38798199e-04,  -3.26213813e-04,   9.42745655e-04,
        -3.54294812e-04,  -6.33464841e-05,  -1.10268515e-03,
         8.89705652e-05,  -1.97948591e-04,   2.35279688e-04,
        -1.39598510e-04,  -3.02472558e-05,   1.00916480e-03,
         6.21443410e-04,  -9.96722037e-04,   1.85572841e-05,
         1.69922508e-04,  -1.23960147e-03,  -1.64589378e-03,
        -3.04421373e-04,   1.49934721e-04,   2.06979799e-04,
         1.57490516e-04,  -1.31658846e-03,  -1.59920373e-04,
         9.56638511e-04,  -5.70123190e-04,   3.57037797e-05,
        -4.63363609e-04,  -8.33105489e-04,  -5.79060834e-04,
        -3.03369111e-04,   9.90447358e-05,  -1.48196897e-06,
        -3.77306254e-04,   1.59475688e-04,  -7.70595871e-04,
        -6.49282468e-04,  -2.96568905e-04,   2.64402339e-04,
         8.13838221e-05,   8.83733698e-04,  -9.40413478e-04,
         5.94693462e-04,   4.22055914e-05,   1.32463181e-04,
        -7.94356965e-04,  -6.16375167e-04,  -4.70002894e-04,
        -7.03099991e-04,  -6.13119945e-04,   2.60717695e-05,
        -4.14311987e-04,   1.58170365e-04,   4.91614243e-04,
         2.24267232e-04,   1.57725540e-04,   1.21462611e-04,
         6.65510806e-04,  -1.45689303e-04,   1.02850012e-04,
         3.58216308e-04,  -1.52825745e-04,   1.03698337e-04,
        -4.74762460e-04,   1.91036440e-04,  -3.83125603e-04,
         5.20996508e-05,   2.46819564e-04,   3.90400818e-05,
        -1.25827112e-04,   4.40346930e-04,  -5.81302017e-04,
        -2.53596357e-04,   5.99939379e-04,  -6.64204923e-04,
         2.91713778e-04,   4.78678459e-04,   2.41885569e-05,
        -1.08367781e-04,   2.30365714e-04,  -1.62678329e-03,
        -2.65515106e-04,   1.83398045e-04,   2.88217002e-04,
        -5.60774600e-04,   2.75219618e-04,  -5.41768050e-04,
        -6.93218401e-06,   2.35481748e-04,  -8.48319598e-06,
         3.46224805e-04,  -2.17045885e-04,  -2.20191983e-04,
        -2.48674190e-04,   8.82383778e-04,   9.53385203e-05,
        -1.68044211e-06,  -6.91149595e-05,  -8.11208749e-04,
        -7.27219403e-04,  -1.01804085e-04,  -2.41651242e-04,
        -6.42025997e-04,  -1.23842416e-04,   5.78997190e-04,
         1.41548342e-04,  -2.92178130e-04,  -6.04660109e-05,
         6.85053480e-05,  -5.20064501e-04,   3.28793748e-04,
         1.63748410e-04,   2.64921828e-04,  -7.29132958e-04,
         7.72168245e-04,   1.93438569e-04,  -1.26465500e-04,
         3.16573325e-04,  -4.45536033e-04,   4.28051932e-04,
        -4.52456547e-04,   1.15817109e-03,  -6.53562404e-04,
         8.43574979e-04,  -5.20991476e-04,   3.71582519e-04,
         3.89014609e-04,  -3.06726788e-04,  -1.50848582e-04,
        -2.33440949e-04,  -2.18167836e-04,   2.36871027e-04,
         5.21267692e-04,  -3.37174127e-04,   4.67583803e-04,
        -2.92314540e-04,   2.68149557e-04,  -2.90837518e-04,
         2.36880069e-04,   6.68799904e-04,   1.60313533e-04,
         4.96127705e-04,  -2.16548230e-05,   3.95299507e-05,
         6.40970596e-04,  -6.31790651e-04,   1.36285009e-03,
        -3.77993860e-04,   1.29781018e-04,  -3.75533684e-04,
         6.17104766e-04,   3.49204302e-04,  -3.92913944e-04,
        -1.36362093e-04,  -9.03910609e-04,   1.63871436e-04,
         4.43133752e-05,   1.80947751e-04,   4.42083071e-04,
        -4.33113283e-04,   4.27834484e-04,  -6.07234780e-04,
        -7.86328721e-04,  -3.69450564e-04,   2.71098711e-04,
         1.43308343e-04,   1.71114198e-04,  -4.29702032e-04,
         4.81791202e-06,   8.13784736e-04,   4.14267608e-04,
         4.57478587e-04,   1.33293842e-04,   2.20344350e-04,
         2.65000493e-04,  -1.31595061e-04,  -2.28873569e-04,
         8.35396481e-04,  -4.08057982e-04,   8.61953924e-05,
         1.24155162e-04,  -1.69573358e-04,  -3.15460448e-04,
         3.84096292e-04,  -4.81712983e-04,   3.40433364e-04,
         1.38979202e-04,  -3.96488978e-04,  -6.35116217e-05,
        -4.35171681e-04,   6.23621294e-04,  -5.69421955e-05,
        -1.78828783e-04,   3.69869803e-04,  -3.74278311e-03,
        -5.75784442e-04,   4.70900358e-04,  -4.89798621e-04,
         8.55338918e-04,  -1.82233179e-04,   4.84297135e-04,
        -1.75193336e-04,   8.67196298e-04,  -3.77545188e-04,
        -6.72743877e-04,   2.77405670e-04,   1.87435731e-04,
        -7.84535684e-04,   8.18930919e-04,   3.83759863e-04,
         8.18409713e-04,  -7.47196315e-05,  -2.60650777e-04,
         1.13880587e-04,  -4.97529934e-04]) # ~ 6813.2176032 (yes, this is positive. remember this is only proportional to the true log posterior)
    if softplus_transform:
        rval_lpost.opt_0_01[0] = log(exp(rval_lpost.opt_0_01[0]) - 1)

    return (rval_lpost, rval_lgrad, rval_lp_lgrad)







class PlainPropDistr(object):
    def __init__(self, def_ratio, mu, K):
        self.def_ratio = def_ratio
        self.def_prop_dist = dist.mvt(mu, K*1.5, 25)
        self.prop_dist = dist.mvnorm(mu, K)
    
    def logpdf(self, s):
        return logsumexp([self.def_prop_dist.logpdf(s) + log(self.def_ratio),
                           self.prop_dist.logpdf(s) + log(1-self.def_ratio)],0)
    def rvs(self, num_samps):
        def_num_samps = int(num_samps * self.def_ratio)
        nondef_num_samps = num_samps - def_num_samps
        samps = self.prop_dist.rvs(nondef_num_samps)
        if self.def_ratio > 0:
            samps = np.vstack([samps, self.def_prop_dist.rvs(def_num_samps)])
        
        return samps

class HlrPropDistr(object):
    def __init__(self, def_ratio, mu):
        self.def_ratio = 0.1
        self.def_sigsq_dist = stats.norm(invsoftplus(mu[0]), 20)
        self.def_rest_dist = dist.mvt(mu[1:], np.eye(mu.size - 1)*20, 10)
        self.sigsq_dist = stats.norm(invsoftplus(mu[0]), 3)
        self.rest_dist = dist.mvnorm(mu[1:], np.eye(mu.size - 1)*4)
    
    def logpdf(self, s):
        
        first = invsoftplus(s[:,0])
        rval = logsumexp([self.def_sigsq_dist.logpdf(first) + self.def_rest_dist.logpdf(s[:, 1:]) + log(self.def_ratio),
                           self.sigsq_dist.logpdf(first) + self.rest_dist.logpdf(s[:, 1:]) + log(1.-self.def_ratio)],0)
        return rval
        
    def rvs(self, num_samps):
        def_num_samps = int(num_samps * self.def_ratio)
        nondef_num_samps = num_samps - def_num_samps
        samps = np.hstack([self.sigsq_dist.rvs(nondef_num_samps)[:, np.newaxis], self.rest_dist.rvs(nondef_num_samps)])
        if self.def_ratio > 0:
            samps = np.vstack([samps,
                               np.hstack([self.def_sigsq_dist.rvs(def_num_samps)[:, np.newaxis], self.def_rest_dist.rvs(def_num_samps)])])
        
        samps[:,0] = softplus(samps[:,0])
        assert(np.all(samps[:, 0]>0))
        return samps

def ess(lw):
    return exp(-(logsumexp((lw - logsumexp(lw))*2)))

def credit_simple_is(name_dataset, num_samps, prop_dist = None):
    def_ratio = 0.1    
    if name_dataset == "plain":
        (f, _, _, hess) = credit_plain_theano(10)
        if prop_dist is None:
            prop_dist =  PlainPropDistr(0.1, f.opt10, np.linalg.inv(-hess(f.opt10))) #PlainPropDistr(0.1, m3)
    elif name_dataset == "hlr":
        (f, _, _, hess) = credit_hlr_theano(0.01)
        K = np.linalg.inv(-hess(f.opt_0_01))
        K = K + np.diag([-np.min(np.diag(K))*1.5]*302)
        K = np.eye(302)*0.00001
        prop_dist = dist.transform.softplus(dist.mvnorm(f.opt_0_01, K), [0])
        
    samps = prop_dist.rvs(num_samps)
    lprop = prop_dist.logpdf(samps)[:, None]
    lpost = np.apply_along_axis(f, 1, samps)
    lw = lpost - lprop
    assert(np.all(1- np.isnan(lw)))
    lw_norm = lw - logsumexp(lw)
    
    w_norm = exp(lw_norm)
    mu = np.sum(samps*w_norm, 0)
    var = np.sum((samps-mu)**2*w_norm, 0)
    var_var = np.sum(((samps-mu)**2-var)**2*w_norm, 0)
    print("expectation", mu, var)
    print("ess:", ess(lw))
    return {"mu": mu, "var": var, "var_var":var_var, "samps":samps, "lw":lw, "w_norm":w_norm}